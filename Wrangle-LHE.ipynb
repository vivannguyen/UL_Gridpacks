{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abraham Tishelman-Charny, 3 March 2021.\n",
    "\n",
    "The purpose of this notebook is to validate resonant HH UL gridpacks. This notebook wrangles data from events in a file and saves the output to a csv. This can also be used to study any [MadGraph5](https://launchpad.net/mg5amcnlo) gridpacks. Thanks to [plyhe docs](https://pydoc.net/pylhe/0.0.2/pylhe/) and [scikit-hep z peak tutorial](https://github.com/scikit-hep/pylhe/blob/master/examples/zpeak.ipynb).\n",
    "\n",
    "Updated by Vivan Nguyen, 26 March 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.12/06\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pylhe\n",
    "import ROOT\n",
    "from ROOT import TLorentzVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make pyLHE file opener to close file properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Write a close function to close files correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pyLHEFileOpener(file):\n",
    "    def __init__(self, file_name):\n",
    "        self.f = pylhe.readLHE(file_name)\n",
    "    def __enter__(self):\n",
    "        return self.f\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        self.f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the LHE files assuming directory tree stree: LHE_Files/<gridpack_Type>/<files>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found file: LHE_Files/GF_NMSSM/NMSSM_XYH_bbZZ_MX_300_MY_170_slc7_amd64_gcc700_CMSSW_10_6_19_tarball.lhe\n",
      "N files: 1\n"
     ]
    }
   ],
   "source": [
    "gridpack_type = 'GF_NMSSM'\n",
    "#gridpack_type = \"GF_Spin-0\"\n",
    "# gridpack_type = \"GF_Spin-2\"\n",
    "# gridpack_type = \"VBF_Spin-0\"\n",
    "# gridpack_type = \"VBF_Spin-2\"\n",
    "\n",
    "def get_files(gridpack_type: str):\n",
    "    \"\"\"Returns files based on gridpack.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gridpack_type : str\n",
    "        Type of gridpack specifying where particles come from.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    files : list\n",
    "        List of files to wrangle.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = ['LHE_Files/%s/%s' % (gridpack_type, file)\n",
    "             for file in os.listdir('./LHE_Files/%s' % (gridpack_type))\n",
    "             if file.endswith('.lhe')]\n",
    "    return files\n",
    "\n",
    "files = get_files(gridpack_type)\n",
    "for f in files:\n",
    "    print('Found file:', f)\n",
    "print('N files:', len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters\n",
    "\n",
    "The global parameters set whether or not to debug and how many events to use. Additionally, they set which variables to save for each individual particle of interest and which particle families have leading and subleading particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False     \n",
    "MAX_EVENTS = 100\n",
    "\n",
    "# Define variables to save for each particle\n",
    "VARIABLES = ['px', 'py', 'pz', \n",
    "             'e', 'm', 'spin',\n",
    "             'status', 'lifetime', 'pt']\n",
    "\n",
    "# Define particles to determine leading and subleading\n",
    "DOUBLE_PARTICLE_DICT = {'GF_NMSSM': ['H', 'g']}  \n",
    "\n",
    "PARTICLE_DICTIONARY = {'GF_NMSSM': ['X', 'Lead_H',\n",
    "                                  'Sublead_H','Lead_g',\n",
    "                                  'Sublead_g']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for event loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pt(p):\n",
    "    \"\"\"Computes the transverse momentum.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    p : Particle\n",
    "        An instance of the Particle class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pt : np.float64\n",
    "        Transverse momentum.\n",
    "    \"\"\"\n",
    "    \n",
    "    px = p.px\n",
    "    py = p.py \n",
    "    pt = np.sqrt(px**2 + py**2)\n",
    "    return pt\n",
    "\n",
    "def get_delta_r(eta1: float, eta2: float, phi1: float, phi2: float):\n",
    "    \"\"\"Returns the delta R between two particles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    eta1 : float\n",
    "        Eta of the first particle.\n",
    "    eta2 : float\n",
    "        Eta of the second particle.\n",
    "    phi1 : float\n",
    "        Phi of the first particle.\n",
    "    phi2 : float\n",
    "        Phi of the second particle.\n",
    "    \"\"\"\n",
    "    \n",
    "    dr = np.sqrt((eta1 - eta2)**2 + (phi1 - phi2)**2)\n",
    "    return dr\n",
    "\n",
    "def debug_message(particle):\n",
    "    \"\"\"Prints the attributes of a particle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    particle : Particle\n",
    "        An instance of the particle class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\npdgId:', particle.id)\n",
    "    print('mass:', particle.m)\n",
    "    for var in ['mother1', 'mother2', 'color1', 'color2',\n",
    "                'status', 'lifetime', 'px', 'py', 'pz', 'spin']:\n",
    "        print('%s: %s' % (var, vars(particle)[var]))\n",
    "    \n",
    "def wrangle_double_particles(d: dict, particle_type: str, particles):\n",
    "    \"\"\"Saves wrangling performed on the leading and subleading particles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dict : dict\n",
    "        Dictionary containing wrangled information about events.\n",
    "    particle_type : str\n",
    "        String defining whether it's a Higgs, gluon, etc. pair.\n",
    "    particle : list\n",
    "        List of particles\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sort particles by descending pt.\n",
    "    pts = [get_pt(particle) for particle in particles]\n",
    "    if particle_type == 'H':\n",
    "        sorted_idxs = np.argsort(pts)[::-1]\n",
    "    else:\n",
    "        sorted_idxs = np.arange(len(particles))\n",
    "    lead_particle = particles[sorted_idxs[0]]\n",
    "    sublead_particle = particles[sorted_idxs[1]]\n",
    "\n",
    "    \n",
    "    #  Record leading and subleading attributes.\n",
    "    for idx, rank in enumerate(['Lead', 'Sublead']):\n",
    "        for var in VARIABLES:\n",
    "            if var == 'pt':\n",
    "                d['_'.join([rank, particle_type, var])].append(pts[sorted_idxs[idx]])\n",
    "            else:\n",
    "                d['_'.join([rank, particle_type, var])].append(vars(particles[sorted_idxs[idx]])[var])\n",
    "    \n",
    "    #  Calculate delta R\n",
    "    lead_tlv = TLorentzVector()\n",
    "    sublead_tlv = TLorentzVector()\n",
    "    \n",
    "    for idx, tlv in enumerate([lead_tlv, sublead_tlv]):\n",
    "        tlv.SetPxPyPzE(vars(particles[sorted_idxs[idx]])['px'],\n",
    "                       vars(particles[sorted_idxs[idx]])['py'],\n",
    "                       vars(particles[sorted_idxs[idx]])['pz'],\n",
    "                       vars(particles[sorted_idxs[idx]])['e'])\n",
    "        \n",
    "    for tlv, rank in zip([lead_tlv, sublead_tlv], ['Lead', 'Sublead']):\n",
    "        d['_'.join([rank, particle_type, 'eta'])].append(tlv.Eta())\n",
    "        d['_'.join([rank, particle_type, 'phi'])].append(tlv.Phi())\n",
    "        \n",
    "    delta_eta = float(lead_tlv.Eta() - sublead_tlv.Eta())\n",
    "    delta_phi = float(lead_tlv.Phi() - sublead_tlv.Phi())\n",
    "    \n",
    "    delta_r = get_delta_r(lead_tlv.Eta(), sublead_tlv.Eta(),\n",
    "                          lead_tlv.Phi(), sublead_tlv.Phi())\n",
    "    \n",
    "    if particle_type == 'H':\n",
    "        d['DR_H1H2'].append(delta_r)\n",
    "        d['H1H2_Deta'].append(delta_eta)\n",
    "        d['H1H2_Dphi'].append(delta_phi)\n",
    "    elif particle_type == 'Outgoing_q':\n",
    "        d['DR_OutqOutq'].append(delta_r)\n",
    "        d['OutqOutq_Deta'].append(delta_eta)\n",
    "        d['OutqOutq_Dphi'].append(delta_phi)\n",
    "    elif particle_type == 'Incoming_q':\n",
    "        d['DR_InqInq'].append(delta_r)\n",
    "        d['InqInq_Deta'].append(delta_eta)\n",
    "        d['InqInq_Dphi'].append(delta_phi) \n",
    "            \n",
    "def wrangle_resonant_particle(d: dict, particle):\n",
    "    \"\"\"Saves wrangling performed on the resonant particle.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_dict : dict\n",
    "        Dictionary containing wrangled information about events.\n",
    "    particle : Particle\n",
    "        The resonant particle.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    for var in VARIABLES:\n",
    "        str_var = 'X_%s' % (var)\n",
    "        if(var == \"pt\"):\n",
    "            x_pt = get_pt(particle)\n",
    "            d[str_var].append(x_pt)\n",
    "        else:\n",
    "            d[str_var].append(vars(particle)[var])\n",
    "\n",
    "    x_tlv = TLorentzVector() \n",
    "    x_tlv.SetPxPyPzE(vars(particle)['px'], vars(particle)['py'],\n",
    "                     vars(particle)['pz'], vars(particle)['e'])\n",
    "    d['X_eta'].append(x_tlv.Eta())\n",
    "    d['X_phi'].append(x_tlv.Phi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_dictionary(gridpack_type: str):\n",
    "    \"\"\"Initialize dictionary that contains wrangle information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    gridpack_type : str\n",
    "        Type of gridpack which specifies what is the resonant particle\n",
    "        and which families of particles contain a leading and subleading pair.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    d : dict\n",
    "        Dictionary for saving information.\n",
    "    \"\"\"\n",
    "    \n",
    "    d = {}\n",
    "    \n",
    "    particle_names = PARTICLE_DICTIONARY[gridpack_type]\n",
    "    double_particles = DOUBLE_PARTICLE_DICT[gridpack_type]\n",
    "    \n",
    "    # Initialize dictionary lists \n",
    "    for p in particle_names:\n",
    "        for v in VARIABLES:\n",
    "            column_name = '_'.join([p,v])\n",
    "            d[column_name] = []\n",
    "    \n",
    "    # Save eta and phi for X, both Higgs \n",
    "    for ang_particle in ['X', 'Lead_H', 'Sublead_H', 'Lead_g', 'Sublead_g']:\n",
    "        for ang_var in ['eta', 'phi','pt']:\n",
    "            d['_'.join([ang_particle, ang_var])] = []\n",
    "            \n",
    "    # For both GF and VBF, initialize lists to save event\n",
    "    # by event pdgIds, DR(H, H), Deta(HH), Dphi(HH)\n",
    "    d['pdgIds'] = []\n",
    "    d['DR_H1H2'] = []\n",
    "    d['H1H2_Deta'] = []\n",
    "    d['H1H2_Dphi'] = []\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(in_file: str, outname: str, debug: bool = False, max_events: int = 100):\n",
    "    \"\"\"Wrangles information from events in a file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    in_file : str\n",
    "        Name of the file to wrangle.\n",
    "    outname : str\n",
    "        Name of file to save to.\n",
    "    debug : bool, optional\n",
    "        Specifies whether or not to print each particle's information in an event.\n",
    "    max_events : int, optional\n",
    "        Provides a limit to how many events in a file should be wrangled.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    d = initialize_dictionary(gridpack_type)\n",
    "    \n",
    "    with pyLHEFileOpener(in_file) as f:\n",
    "        for eidx, event in enumerate(f):\n",
    "        #for eidx, event in enumerate(pylhe.readLHE(in_file)):\n",
    "            # TODO: Implement module which has a progress bar like tqdm,\n",
    "            # which shows completion progress and also estimated time left?\n",
    "            # Then you would have the following without the next two lines:\n",
    "            # for eidx, event in enumerate(tqdm(pylhe.readLHE(in_file))):\n",
    "            if eidx % 1000 == 0:\n",
    "                print('On event', eidx)\n",
    "            if eidx == max_events:\n",
    "                print('Stopping at %s events' % (max_events))\n",
    "                break\n",
    "\n",
    "            #  Place the debug check outside the other for loop,\n",
    "            #  so it is checked only once. Who cares if you're\n",
    "            #  looping over all the particles again. It's going to\n",
    "            #  take longer anyway since we're printing stuff.\n",
    "            if debug:\n",
    "                for particle in event.particles:\n",
    "                    debug_message(particle)\n",
    "\n",
    "            pdg_ids = [particle.id for particle in event.particles]\n",
    "            np_pdg_ids = np.array(pdg_ids, dtype=np.int16)\n",
    "            # This avoids all the unnecessary looping over particles\n",
    "            # which are not True for any of the if statements.\n",
    "            # TODO: There's probably a better way of doing this\n",
    "            #       than typing them in by hand that doesn't suffer\n",
    "            #       in computational time. Using sums doesn't seem\n",
    "            #       to be the way to go because they check conditions individually.\n",
    "            special_idxs = np.where((np_pdg_ids == 21)\n",
    "                                    | (np_pdg_ids == 25)\n",
    "                                    | (np_pdg_ids == 35)\n",
    "                                    | (np_pdg_ids == 45))[0]\n",
    "\n",
    "            gluons = []\n",
    "            higgs_bosons = []\n",
    "\n",
    "            for special_idx in special_idxs:\n",
    "                particle = event.particles[special_idx]\n",
    "\n",
    "                if (particle.id == 21) and (\"GF\" in gridpack_type):\n",
    "                    gluons.append(particle)\n",
    "                elif particle.id == 25:\n",
    "                    higgs_bosons.append(particle)\n",
    "                elif particle.id == 35:\n",
    "                    higgs_bosons.append(particle)\n",
    "                # Spin-0 or Spin-2 Resonant Particle, \n",
    "                # X->YH resonant particle\n",
    "                elif particle.id == 45:\n",
    "                    resonant_particle = particle \n",
    "\n",
    "            wrangle_double_particles(d, 'H', higgs_bosons)\n",
    "            wrangle_double_particles(d, 'g', gluons)                   \n",
    "            wrangle_resonant_particle(d, resonant_particle)\n",
    "\n",
    "            d['pdgIds'].append(pdg_ids)\n",
    "    pd.DataFrame(d).to_csv(outname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-54-395a45db825e>\", line 4, in <module>\n",
      "    test=process_file(f, outname, debug=DEBUG, max_events=MAX_EVENTS)\n",
      "  File \"<ipython-input-40-5df7a214f263>\", line 23, in process_file\n",
      "    for eidx, event in enumerate(f):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/pylhe/__init__.py\", line 168, in readLHE\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/xml/etree/ElementTree.py\", line 1242, in iterparse\n",
      "OSError: [Errno 24] Too many open files: 'LHE_Files/GF_NMSSM/NMSSM_XYH_bbZZ_MX_300_MY_170_slc7_amd64_gcc700_CMSSW_10_6_19_tarball.lhe'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "  File \"/usr/local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 725, in getmodule\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "  File \"/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/posixpath.py\", line 376, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: 'LHE_Files/GF_NMSSM/NMSSM_XYH_bbZZ_MX_300_MY_170_slc7_amd64_gcc700_CMSSW_10_6_19_tarball.lhe'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "outname = 'new.csv'\n",
    "\n",
    "for f in files:\n",
    "    test=process_file(f, outname, debug=DEBUG, max_events=MAX_EVENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the 'pdgIds' column contains lists, you will need to convert that so it is read in correctly by pandas as a list instead of a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(outname, converters={'pdgIds': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (pd.read_csv('/Users/vivannguyen/Downloads/df_300_170.csv',\n",
    "                   converters={'pdgIds':eval})\n",
    "       .drop('Unnamed: 0', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.0, 21.0, 45.0, 35.0, 25.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].pdgIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.0, 21.0, 45.0, 35.0, 25.0]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[0].pdgIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
